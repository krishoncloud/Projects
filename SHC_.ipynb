{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "VBRqDU1ih5KP",
        "outputId": "d16dc4b9-c950-4d60-b5c8-791b5b29face"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'patient_health_data.csv'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "import os\n",
        "\n",
        "# Sample names for diversity\n",
        "male_names = [\n",
        "    \"Amit\", \"Ravi\", \"Vikas\", \"Deepak\", \"Manoj\", \"Arjun\", \"Sanjay\", \"Prakash\", \"Vinod\", \"Rohit\",\n",
        "    \"Rajesh\", \"Suresh\", \"Mahesh\", \"Ramesh\", \"Karan\", \"Harsh\", \"Nitin\", \"Yash\", \"Pankaj\", \"Sumit\",\n",
        "    \"Ankit\", \"Tarun\", \"Gaurav\", \"Kapil\", \"Abhishek\", \"Sachin\", \"Rahul\", \"Sameer\", \"Aditya\", \"Siddharth\",\n",
        "    \"Lokesh\", \"Bhavesh\", \"Akhil\", \"Parth\", \"Tushar\", \"Varun\", \"Rajat\", \"Dev\", \"Aarav\", \"Krishna\",\n",
        "    \"Shubham\", \"Ashish\", \"Dinesh\", \"Uday\", \"Alok\", \"Bharat\", \"Kunal\", \"Suraj\", \"Vivek\", \"Lalit\"\n",
        "]\n",
        "female_names = [\n",
        "    \"Rekha\", \"Kavita\", \"Pooja\", \"Neha\", \"Anjali\", \"Priya\", \"Sunita\", \"Meena\", \"Divya\", \"Sapna\",\n",
        "    \"Sneha\", \"Ritu\", \"Nisha\", \"Anita\", \"Simran\", \"Aarti\", \"Bhavna\", \"Komal\", \"Preeti\", \"Rashmi\",\n",
        "    \"Swati\", \"Payal\", \"Sheetal\", \"Shilpa\", \"Monika\", \"Geeta\", \"Radhika\", \"Jyoti\", \"Seema\", \"Archana\",\n",
        "    \"Tina\", \"Laxmi\", \"Usha\", \"Suman\", \"Kiran\", \"Pallavi\", \"Megha\", \"Riya\", \"Manisha\", \"Varsha\",\n",
        "    \"Kirti\", \"Sarita\", \"Sonia\", \"Chitra\", \"Damini\", \"Alisha\", \"Hemlata\", \"Tanvi\", \"Ishita\", \"Harshita\"\n",
        "]\n",
        "last_names = [\n",
        "    \"Sharma\", \"Verma\", \"Gupta\", \"Yadav\", \"Rao\", \"Singh\", \"Agarwal\", \"Choudhary\", \"Patel\", \"Nair\",\n",
        "    \"Iyer\", \"Mehta\", \"Tripathi\", \"Joshi\", \"Bansal\", \"Malhotra\", \"Kohli\", \"Thakur\", \"Mishra\", \"Dubey\",\n",
        "    \"Goyal\", \"Rawat\", \"Reddy\", \"Kapoor\", \"Chopra\", \"Vijay\", \"Bhatia\", \"Pandey\", \"Saxena\", \"Tiwari\",\n",
        "    \"Kulkarni\", \"Deshmukh\", \"Pawar\", \"Sethi\", \"Mathur\", \"Srivastava\", \"Das\", \"Roy\", \"Banerjee\", \"Chatterjee\",\n",
        "    \"Naidu\", \"Menon\", \"Dutta\", \"Sen\", \"Mukherjee\", \"Kumar\", \"Bhatt\", \"Pathak\", \"Jha\", \"Khan\"\n",
        "]\n",
        "\n",
        "\n",
        "# Categorical options for fields\n",
        "smoking_status_options = [\n",
        "    \"Non-smoker\", \"Ex-smoker\", \"Light Smoker\", \"Moderate Smoker\", \"Heavy Smoker\",\n",
        "    \"Social Smoker\", \"Occasional Smoker\", \"Trying to Quit\", \"Vaper (Nicotine)\", \"Dual User (Cigarette + Vaper)\"\n",
        "]\n",
        "alcohol_options = [\n",
        "    \"None\", \"Occasional\", \"Moderate\", \"Frequent\", \"Heavy\",\n",
        "    \"Social Drinker\", \"Binge Drinker\", \"Weekend Drinker\", \"Rare Drinker\", \"Alcohol Dependent\"\n",
        "]\n",
        "exercise_options = [\n",
        "    \"None\", \"Light\", \"Moderate\", \"Regular\", \"Intense\",\n",
        "    \"Yoga Only\", \"Walking Daily\", \"Gym 2-3 times/week\", \"Athlete\", \"Sedentary\"\n",
        "]\n",
        "\n",
        "conditions_options = [\n",
        "    \"None\", \"Hypertension\", \"Diabetes\", \"Heart Disease\", \"Kidney Disease\",\n",
        "    \"Hypertension, Diabetes\", \"Hypertension, Heart Disease\", \"Diabetes, Kidney Disease\",\n",
        "    \"Hypertension, Kidney Disease\", \"Heart Disease, Kidney Disease\",\n",
        "    \"Asthma\", \"Obesity\", \"COPD\", \"Thyroid Disorder\", \"Cancer History\",\n",
        "    \"Hypertension, Obesity\", \"Diabetes, Obesity\", \"Hypertension, Diabetes, Obesity\",\n",
        "    \"Autoimmune Disease\", \"Arthritis\"\n",
        "]\n",
        "medications_options = [\n",
        "    \"None\", \"BP Meds\", \"Insulin\", \"Aspirin\", \"BP Meds, Insulin\",\n",
        "    \"Cholesterol Meds\", \"Blood Thinners\", \"Diuretics\", \"Beta Blockers\", \"ACE Inhibitors\",\n",
        "    \"Metformin\", \"Statins\", \"Painkillers (NSAIDs)\", \"Thyroid Meds\", \"Antidepressants\",\n",
        "    \"Hypertension Combo Therapy\", \"Diabetes Combo Therapy\", \"Heart Disease Drugs\",\n",
        "    \"Kidney Disease Drugs\", \"Anticoagulants\"\n",
        "]\n",
        "\n",
        "complaints_options = [\n",
        "    \"None\", \"Chest Pain\", \"Dizziness\", \"Fatigue\", \"Headache\",\n",
        "    \"Shortness of Breath\", \"Palpitations\", \"Swelling in Legs\", \"Blurred Vision\", \"Nausea\",\n",
        "    \"Chest Tightness\", \"Fainting\", \"Sudden Weakness\", \"Numbness in Limbs\", \"Back Pain\",\n",
        "    \"Joint Pain\", \"Abdominal Pain\", \"Insomnia\", \"Frequent Urination\", \"Rapid Weight Loss\"\n",
        "]\n",
        "\n",
        "# Generating 50 records\n",
        "records = []\n",
        "for i in range(1, 30001):\n",
        "    gender = random.choice([\"Male\", \"Female\"])\n",
        "    if gender == \"Male\":\n",
        "        first_name = random.choice(male_names)\n",
        "    else:\n",
        "        first_name = random.choice(female_names)\n",
        "    last_name = random.choice(last_names)\n",
        "    patient_id = f\"SHC{i:03d}\"\n",
        "    age = random.randint(25, 75)\n",
        "    family_history = random.choice([\"Yes\", \"No\"])\n",
        "    bp_systolic = random.randint(110, 180)\n",
        "    bp_diastolic = random.randint(70, 110)\n",
        "    blood_sugar = random.randint(80, 250)\n",
        "    cholesterol = random.randint(140, 300)\n",
        "    bmi = round(random.uniform(18.5, 35.0), 1)\n",
        "    smoking_status = random.choice(smoking_status_options)\n",
        "    alcohol_consumption = random.choice(alcohol_options)\n",
        "    exercise_level = random.choice(exercise_options)\n",
        "    existing_conditions = random.choice(conditions_options)\n",
        "    medications = random.choice(medications_options)\n",
        "    heart_rate = random.randint(60, 100)\n",
        "    ecg_abnormality = random.choice([\"Yes\", \"No\"])\n",
        "    recent_complaints = random.choice(complaints_options)\n",
        "    hospital_visits = random.randint(0, 5)\n",
        "\n",
        "    records.append([\n",
        "        patient_id, first_name, last_name, age, gender, family_history, bp_systolic, bp_diastolic,\n",
        "        blood_sugar, cholesterol, bmi, smoking_status, alcohol_consumption, exercise_level,\n",
        "        existing_conditions, medications, heart_rate, ecg_abnormality, recent_complaints, hospital_visits\n",
        "    ])\n",
        "\n",
        "# Creating DataFrame\n",
        "columns = [\n",
        "    \"Patient_ID\", \"First_Name\", \"Last_Name\", \"Age\", \"Gender\", \"Family_History\", \"BP_Systolic\", \"BP_Diastolic\",\n",
        "    \"Blood_Sugar\", \"Cholesterol\", \"BMI\", \"Smoking_Status\", \"Alcohol_Consumption\", \"Exercise_Level\",\n",
        "    \"Existing_Conditions\", \"Medications\", \"Heart_Rate\", \"ECG_Abnormality\", \"Recent_Complaints\", \"Hospital_Visits\"\n",
        "]\n",
        "df = pd.DataFrame(records, columns=columns)\n",
        "\n",
        "# Saving to CSV in the current working directory\n",
        "csv_path = \"patient_health_data.csv\"  # Changed the path\n",
        "\n",
        "# Create the directory if it doesn't exist (optional for current directory)\n",
        "if os.path.dirname(csv_path):\n",
        "    os.makedirs(os.path.dirname(csv_path), exist_ok=True)\n",
        "\n",
        "df.to_csv(csv_path, index=False)\n",
        "\n",
        "csv_path\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J1wMCUFSkqIw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lightgbm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SX-WdT26nqtd",
        "outputId": "a6334e6f-fb48-4462-bb9e-0c1ac5fae28e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lightgbm\n",
            "  Downloading lightgbm-4.6.0-py3-none-manylinux_2_28_x86_64.whl.metadata (17 kB)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from lightgbm) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from lightgbm) (1.13.1)\n",
            "Downloading lightgbm-4.6.0-py3-none-manylinux_2_28_x86_64.whl (3.6 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/3.6 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m2.7/3.6 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lightgbm\n",
            "Successfully installed lightgbm-4.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vP36cD8Vnqle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report\n",
        "import random\n",
        "\n",
        "# Load Dataset\n",
        "df = pd.read_csv('patient_health_data.csv')\n",
        "\n",
        "# Encoding categorical features\n",
        "label_encoders = {}\n",
        "categorical_columns = ['Gender', 'Family_History', 'Smoking_Status', 'Alcohol_Consumption', 'Exercise_Level', 'Existing_Conditions', 'Medications', 'ECG_Abnormality', 'Recent_Complaints']\n",
        "\n",
        "for col in categorical_columns:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "    label_encoders[col] = le\n",
        "\n",
        "# Features and dummy target creation for each risk\n",
        "X = df.drop(columns=['Patient_ID', 'First_Name', 'Last_Name'])\n",
        "\n",
        "# Introduce noise to mimic real-world uncertainty\n",
        "def generate_target_risk_with_noise(row):\n",
        "    base_risk = 'Low'\n",
        "    if row['BP_Systolic'] > 150 or row['Cholesterol'] > 240 or row['Heart_Rate'] > 95:\n",
        "        base_risk = 'High'\n",
        "    elif row['BP_Systolic'] > 130 or row['Cholesterol'] > 200:\n",
        "        base_risk = 'Medium'\n",
        "\n",
        "    # Introduce noise\n",
        "    if random.random() < 0.1:  # 10% chance of wrong label\n",
        "        return random.choice(['Low', 'Medium', 'High'])\n",
        "    return base_risk\n",
        "\n",
        "# Creating dummy targets based on simple rules with noise\n",
        "for risk in ['Heart_Attack_Risk', 'Stroke_Risk', 'Diabetic_Complications_Risk', 'Hypertension_Crisis_Risk']:\n",
        "    df[risk] = df.apply(generate_target_risk_with_noise, axis=1)\n",
        "\n",
        "# Training a model for each risk\n",
        "models = {}\n",
        "for risk in ['Heart_Attack_Risk', 'Stroke_Risk', 'Diabetic_Complications_Risk', 'Hypertension_Crisis_Risk']:\n",
        "    y = df[risk]\n",
        "    le_target = LabelEncoder()\n",
        "    y_encoded = le_target.fit_transform(y)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "    train_data = lgb.Dataset(X_train, label=y_train)\n",
        "    test_data = lgb.Dataset(X_test, label=y_test)\n",
        "\n",
        "    params = {\n",
        "        'objective': 'multiclass',\n",
        "        'num_class': 3,\n",
        "        'metric': 'multi_logloss',\n",
        "        'boosting_type': 'gbdt',\n",
        "        'learning_rate': 0.05,\n",
        "        'max_depth': 6,\n",
        "        'num_leaves': 31,\n",
        "        'verbose': -1\n",
        "    }\n",
        "\n",
        "    model = lgb.train(\n",
        "        params,\n",
        "        train_data,\n",
        "        valid_sets=[test_data],\n",
        "        num_boost_round=100,\n",
        "        callbacks=[lgb.early_stopping(stopping_rounds=10)], # Use callbacks for early stopping\n",
        "    )\n",
        "\n",
        "\n",
        "    models[risk] = (model, le_target)\n",
        "\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_classes = [y.argmax() for y in y_pred]\n",
        "\n",
        "    print(f\"\\nClassification Report for {risk}:\")\n",
        "    print(classification_report(y_test, y_pred_classes, target_names=le_target.classes_))\n",
        "\n",
        "print(\"Training Complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKs0g2NJnqOb",
        "outputId": "7ac175c2-2313-4939-b6ec-1fdf5a6b1184"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[63]\tvalid_0's multi_logloss: 0.290026\n",
            "\n",
            "Classification Report for Heart_Attack_Risk:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        High       0.94      0.98      0.96      3915\n",
            "         Low       0.94      0.76      0.84       723\n",
            "      Medium       0.93      0.90      0.91      1362\n",
            "\n",
            "    accuracy                           0.94      6000\n",
            "   macro avg       0.93      0.88      0.90      6000\n",
            "weighted avg       0.93      0.94      0.93      6000\n",
            "\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[66]\tvalid_0's multi_logloss: 0.283176\n",
            "\n",
            "Classification Report for Stroke_Risk:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        High       0.94      0.98      0.96      3908\n",
            "         Low       0.93      0.80      0.86       679\n",
            "      Medium       0.94      0.88      0.91      1413\n",
            "\n",
            "    accuracy                           0.94      6000\n",
            "   macro avg       0.94      0.89      0.91      6000\n",
            "weighted avg       0.94      0.94      0.94      6000\n",
            "\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[65]\tvalid_0's multi_logloss: 0.279977\n",
            "\n",
            "Classification Report for Diabetic_Complications_Risk:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        High       0.94      0.99      0.96      3887\n",
            "         Low       0.94      0.78      0.85       708\n",
            "      Medium       0.94      0.88      0.91      1405\n",
            "\n",
            "    accuracy                           0.94      6000\n",
            "   macro avg       0.94      0.88      0.91      6000\n",
            "weighted avg       0.94      0.94      0.94      6000\n",
            "\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "Early stopping, best iteration is:\n",
            "[73]\tvalid_0's multi_logloss: 0.277301\n",
            "\n",
            "Classification Report for Hypertension_Crisis_Risk:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        High       0.94      0.99      0.96      3875\n",
            "         Low       0.95      0.77      0.85       714\n",
            "      Medium       0.95      0.89      0.92      1411\n",
            "\n",
            "    accuracy                           0.94      6000\n",
            "   macro avg       0.94      0.88      0.91      6000\n",
            "weighted avg       0.94      0.94      0.94      6000\n",
            "\n",
            "Training Complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "#ENTRY 1\n",
        "\n",
        "# Example patient data - AFTER encoding the categorical fields\n",
        "custom_input = pd.DataFrame({\n",
        "    'Age': [55],\n",
        "    'Gender': [label_encoders['Gender'].transform(['Male'])[0]],\n",
        "    'Family_History': [label_encoders['Family_History'].transform(['Yes'])[0]],\n",
        "    'BP_Systolic': [160],\n",
        "    'BP_Diastolic': [95],\n",
        "    'Blood_Sugar': [180],\n",
        "    'Cholesterol': [250],\n",
        "    'BMI': [28],\n",
        "    'Smoking_Status': [label_encoders['Smoking_Status'].transform(['Heavy Smoker'])[0]],\n",
        "    'Alcohol_Consumption': [label_encoders['Alcohol_Consumption'].transform(['Occasional'])[0]],\n",
        "    'Exercise_Level': [label_encoders['Exercise_Level'].transform(['Regular'])[0]],\n",
        "    'Existing_Conditions': [label_encoders['Existing_Conditions'].transform(['Hypertension'])[0]],\n",
        "    'Medications': [label_encoders['Medications'].transform(['BP Meds'])[0]],\n",
        "    'Heart_Rate': [90],\n",
        "    'ECG_Abnormality': [label_encoders['ECG_Abnormality'].transform(['Yes'])[0]],\n",
        "    'Recent_Complaints': [label_encoders['Recent_Complaints'].transform(['Chest Pain'])[0]],\n",
        "    'Hospital_Visits': [0] # Adding the missing 'Hospital_Visits' column\n",
        "})\n",
        "for risk in ['Heart_Attack_Risk', 'Stroke_Risk', 'Diabetic_Complications_Risk', 'Hypertension_Crisis_Risk']:\n",
        "    model, le_target = models[risk]  # Get trained model & LabelEncoder for target\n",
        "    prediction_probs = model.predict(custom_input)  # Get probabilities for each class\n",
        "    predicted_class_index = prediction_probs[0].argmax()  # Index of the highest probability\n",
        "    predicted_class_label = le_target.inverse_transform([predicted_class_index])[0]  # Convert back to 'Low/Medium/High'\n",
        "\n",
        "    print(f\"{risk}: {predicted_class_label}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2mQOyImzSjI",
        "outputId": "d42ea722-dd77-461d-afb6-c285e60074f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Heart_Attack_Risk: High\n",
            "Stroke_Risk: High\n",
            "Diabetic_Complications_Risk: High\n",
            "Hypertension_Crisis_Risk: High\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "# MAKING ANOMALOUS Dataset\n",
        "\n",
        "# Load Dataset\n",
        "df = pd.read_csv('patient_health_data.csv')\n",
        "\n",
        "# Function to inject anomalies into the dataset\n",
        "def inject_anomalies(df, anomaly_fraction=0.03):\n",
        "    df_anomaly = df.copy()\n",
        "    num_anomalies = int(len(df) * anomaly_fraction)\n",
        "    anomaly_indices = random.sample(range(len(df)), num_anomalies)\n",
        "\n",
        "    for idx in anomaly_indices:\n",
        "        choice = random.random()\n",
        "        if choice < 0.25:  # Extreme vitals\n",
        "            df_anomaly.loc[idx, 'BP_Systolic'] = random.randint(220, 300)\n",
        "            df_anomaly.loc[idx, 'BP_Diastolic'] = random.randint(130, 180)\n",
        "            df_anomaly.loc[idx, 'Heart_Rate'] = random.randint(180, 250)\n",
        "        elif choice < 0.5:  # Illogical BMI\n",
        "            df_anomaly.loc[idx, 'BMI'] = random.uniform(5, 60)\n",
        "        elif choice < 0.75:  # Medication & BP mismatch\n",
        "            df_anomaly.loc[idx, 'BP_Systolic'] = random.randint(180, 250)\n",
        "            df_anomaly.loc[idx, 'Medications'] = random.choice(['BP Meds', 'BP Meds, Insulin'])\n",
        "        else:  # Contradictory Lifestyle vs. Obesity\n",
        "            df_anomaly.loc[idx, 'Exercise_Level'] = random.choice(['Moderate', 'Regular'])\n",
        "            df_anomaly.loc[idx, 'BMI'] = random.uniform(40, 60)\n",
        "\n",
        "    return df_anomaly\n",
        "\n",
        "# Apply anomaly injection\n",
        "df_anomalous = inject_anomalies(df, anomaly_fraction=0.03)\n",
        "\n",
        "# Save the anomalous dataset to CSV\n",
        "df_anomalous.to_csv('anomalous.csv', index=False)\n",
        "\n",
        "print(\"Anomalous dataset saved as 'anomalous.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4865YeS9Mx2G",
        "outputId": "88c96d88-553f-4d41-ca8d-bc303095c7de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Anomalous dataset saved as 'anomalous.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import multivariate_normal\n",
        "\n",
        "# Load Anomalous Dataset\n",
        "df_anomalous = pd.read_csv('anomalous.csv')\n",
        "\n",
        "# Drop non-numeric fields\n",
        "X_gaussian = df_anomalous.select_dtypes(include=['float64', 'int64']).copy()\n",
        "\n",
        "# Fit Gaussian Distribution\n",
        "mean = X_gaussian.mean(axis=0)\n",
        "cov = np.cov(X_gaussian, rowvar=False)\n",
        "\n",
        "# Calculate probability density for each data point\n",
        "pdf_values = multivariate_normal(mean=mean, cov=cov).pdf(X_gaussian)\n",
        "\n",
        "# Set epsilon threshold (adjust as needed based on data distribution)\n",
        "epsilon = np.percentile(pdf_values, 3)  # 3% as anomalies\n",
        "\n",
        "# Mark anomalies\n",
        "df_anomalous['Anomaly'] = np.where(pdf_values < epsilon, 'Anomaly', 'Normal')\n",
        "\n",
        "# Save the results with anomalies marked\n",
        "df_anomalous.to_csv('anomalous_with_predictions.csv', index=False)\n",
        "\n",
        "# Display some detected anomalies\n",
        "anomalies_detected = df_anomalous[df_anomalous['Anomaly'] == 'Anomaly']\n",
        "print(anomalies_detected.head())\n",
        "\n",
        "# Evaluate accuracy (assuming 3% of injected anomalies)\n",
        "actual_anomalies = int(len(df_anomalous) * 0.03)  # Since we injected 3%\n",
        "detected_anomalies = len(anomalies_detected)\n",
        "\n",
        "print(f\"Expected Anomalies: {actual_anomalies}\")\n",
        "print(f\"Detected Anomalies: {detected_anomalies}\")\n",
        "\n",
        "precision = detected_anomalies / (detected_anomalies + (len(df_anomalous) - detected_anomalies))\n",
        "recall = detected_anomalies / actual_anomalies\n",
        "f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1_score:.2f}\")\n",
        "\n",
        "print(\"Gaussian anomaly detection complete. Results saved as 'anomalous_with_predictions.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "168zdhxjmwRt",
        "outputId": "6790457f-16e2-446e-a093-6cfa09d65049"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Patient_ID First_Name  Last_Name  Age  Gender Family_History  BP_Systolic  \\\n",
            "24      SHC025      Seema  Choudhary   58  Female             No          228   \n",
            "128     SHC129     Pankaj     Tiwari   30    Male             No          171   \n",
            "159     SHC160       Usha      Dutta   65  Female             No          126   \n",
            "176     SHC177     Shilpa       Nair   59  Female             No          254   \n",
            "320     SHC321    Pallavi     Bansal   38  Female             No          138   \n",
            "\n",
            "     BP_Diastolic  Blood_Sugar  Cholesterol  ...    Smoking_Status  \\\n",
            "24             91          171          247  ...  Vaper (Nicotine)   \n",
            "128           104           80          264  ...   Moderate Smoker   \n",
            "159           101          181          184  ...     Social Smoker   \n",
            "176           141          150          150  ...     Social Smoker   \n",
            "320           105          162          158  ...  Vaper (Nicotine)   \n",
            "\n",
            "    Alcohol_Consumption      Exercise_Level     Existing_Conditions  \\\n",
            "24           Occasional       Walking Daily                 Obesity   \n",
            "128            Moderate             Athlete        Thyroid Disorder   \n",
            "159          Occasional             Regular        Thyroid Disorder   \n",
            "176       Binge Drinker  Gym 2-3 times/week  Hypertension, Diabetes   \n",
            "320            Frequent  Gym 2-3 times/week            Hypertension   \n",
            "\n",
            "          Medications Heart_Rate  ECG_Abnormality Recent_Complaints  \\\n",
            "24   BP Meds, Insulin         88              Yes   Chest Tightness   \n",
            "128      Thyroid Meds         68              Yes         Dizziness   \n",
            "159    Anticoagulants         85               No    Abdominal Pain   \n",
            "176  BP Meds, Insulin        190               No   Sudden Weakness   \n",
            "320    Blood Thinners         87               No               NaN   \n",
            "\n",
            "    Hospital_Visits  Anomaly  \n",
            "24                0  Anomaly  \n",
            "128               0  Anomaly  \n",
            "159               3  Anomaly  \n",
            "176               2  Anomaly  \n",
            "320               2  Anomaly  \n",
            "\n",
            "[5 rows x 21 columns]\n",
            "Expected Anomalies: 900\n",
            "Detected Anomalies: 900\n",
            "Precision: 0.03\n",
            "Recall: 1.00\n",
            "F1 Score: 0.06\n",
            "Gaussian anomaly detection complete. Results saved as 'anomalous_with_predictions.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "# Load Anomalous Dataset\n",
        "df_anomalous = pd.read_csv('anomalous.csv')\n",
        "\n",
        "# Inject anomalies into the dataset (for testing purposes)\n",
        "# For simplicity, let's assume that we inject 3% anomalies at random\n",
        "import numpy as np\n",
        "np.random.seed(42)\n",
        "num_rows = len(df_anomalous)\n",
        "num_anomalies = int(num_rows * 0.03)\n",
        "\n",
        "# Randomly assign True Anomalies\n",
        "true_anomalies = np.zeros(num_rows)\n",
        "anomaly_indices = np.random.choice(df_anomalous.index, num_anomalies, replace=False)\n",
        "true_anomalies[anomaly_indices] = 1\n",
        "\n",
        "# Add True_Anomaly column to the dataframe\n",
        "df_anomalous['True_Anomaly'] = true_anomalies\n",
        "\n",
        "# Drop non-numeric fields for Isolation Forest\n",
        "X_iforest = df_anomalous.select_dtypes(include=['float64', 'int64']).copy()\n",
        "\n",
        "# Train Isolation Forest\n",
        "model_iforest = IsolationForest(n_estimators=100, contamination=0.0382, random_state=42)\n",
        "model_iforest.fit(X_iforest)\n",
        "\n",
        "# Predict Anomalies\n",
        "anomaly_preds = model_iforest.predict(X_iforest)\n",
        "\n",
        "# Add Anomaly Column to DataFrame\n",
        "df_anomalous['Anomaly'] = anomaly_preds\n",
        "\n",
        "# Map Anomalies to Human-readable Labels\n",
        "df_anomalous['Anomaly'] = df_anomalous['Anomaly'].map({1: 'Normal', -1: 'Anomaly'})\n",
        "\n",
        "# Save the results with anomalies marked\n",
        "df_anomalous.to_csv('anomalous_with_predictions.csv', index=False)\n",
        "\n",
        "# Display some detected anomalies\n",
        "anomalies_detected = df_anomalous[df_anomalous['Anomaly'] == 'Anomaly']\n",
        "print(anomalies_detected.head())\n",
        "\n",
        "# Evaluate accuracy using True_Anomaly for comparison\n",
        "detected_anomalies = len(anomalies_detected)\n",
        "\n",
        "# False positives and false negatives\n",
        "false_positives = len(df_anomalous[(df_anomalous['Anomaly'] == 'Anomaly') & (df_anomalous['True_Anomaly'] == 0)])\n",
        "false_negatives = len(df_anomalous[(df_anomalous['Anomaly'] == 'Normal') & (df_anomalous['True_Anomaly'] == 1)])\n",
        "\n",
        "print(f\"Detected Anomalies: {detected_anomalies}\")\n",
        "print(f\"False Positives: {false_positives}\")\n",
        "print(f\"False Negatives: {false_negatives}\")\n",
        "\n",
        "# Precision, Recall, and F1 Score\n",
        "precision = detected_anomalies / (detected_anomalies + false_positives)\n",
        "recall = detected_anomalies / (detected_anomalies + false_negatives)\n",
        "f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1_score:.2f}\")\n",
        "\n",
        "print(\"Isolation Forest anomaly detection complete. Results saved as 'anomalous_with_predictions.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwrCdpNSq-nk",
        "outputId": "13ad97d5-8cfd-4ede-da99-35c36a1e47b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Patient_ID First_Name   Last_Name  Age  Gender Family_History  \\\n",
            "34      SHC035      Anita      Chopra   61  Female             No   \n",
            "173     SHC174      Tanvi      Bansal   65  Female             No   \n",
            "176     SHC177     Shilpa        Nair   59  Female             No   \n",
            "216     SHC217      Megha  Srivastava   27  Female            Yes   \n",
            "217     SHC218      Divya       Vijay   66  Female            Yes   \n",
            "\n",
            "     BP_Systolic  BP_Diastolic  Blood_Sugar  Cholesterol  ...  \\\n",
            "34           140           102          118          246  ...   \n",
            "173          110           103           90          296  ...   \n",
            "176          254           141          150          150  ...   \n",
            "216          169            89          195          251  ...   \n",
            "217          135            91          192          224  ...   \n",
            "\n",
            "     Alcohol_Consumption      Exercise_Level              Existing_Conditions  \\\n",
            "34       Weekend Drinker           Sedentary         Diabetes, Kidney Disease   \n",
            "173           Occasional  Gym 2-3 times/week  Hypertension, Diabetes, Obesity   \n",
            "176        Binge Drinker  Gym 2-3 times/week           Hypertension, Diabetes   \n",
            "216      Weekend Drinker               Light    Heart Disease, Kidney Disease   \n",
            "217             Frequent                 NaN                   Kidney Disease   \n",
            "\n",
            "              Medications Heart_Rate ECG_Abnormality    Recent_Complaints  \\\n",
            "34         Anticoagulants         73             Yes               Nausea   \n",
            "173  Kidney Disease Drugs         85             Yes  Shortness of Breath   \n",
            "176      BP Meds, Insulin        190              No      Sudden Weakness   \n",
            "216        Blood Thinners         77             Yes             Fainting   \n",
            "217  Painkillers (NSAIDs)         66              No             Insomnia   \n",
            "\n",
            "    Hospital_Visits True_Anomaly  Anomaly  \n",
            "34                4          1.0  Anomaly  \n",
            "173               5          1.0  Anomaly  \n",
            "176               2          0.0  Anomaly  \n",
            "216               0          1.0  Anomaly  \n",
            "217               2          1.0  Anomaly  \n",
            "\n",
            "[5 rows x 22 columns]\n",
            "Detected Anomalies: 1146\n",
            "False Positives: 332\n",
            "False Negatives: 86\n",
            "Precision: 0.78\n",
            "Recall: 0.93\n",
            "F1 Score: 0.85\n",
            "Isolation Forest anomaly detection complete. Results saved as 'anomalous_with_predictions.csv'\n"
          ]
        }
      ]
    }
  ]
}